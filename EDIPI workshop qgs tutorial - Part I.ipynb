{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDIPI Workshop qgs tutorial - Part I: Computing the correlation properties of the system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the second one of a tutorial given during the EDIPI workshop at RMI in January 2023.\n",
    "In this tutorial, you will learn:\n",
    "\n",
    "1. How to install the [qgs](https://github.com/Climdyn/qgs) framework for low-order climate and weather modeling\n",
    "2. How to run the model\n",
    "3. **How to compute the correlation properties of the underlying dynamical model**\n",
    "4. How to compute the Largest Lyapunov Exponent (LLE) in the model\n",
    "5. How to compute the full Lyapunov Exponent spectrum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will be concerned with task 3 above: learning how to compute the autocorrelation of variables in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that you have already been through the [Introduction notebook](https://github.com/jodemaey/EDIPI-qgs-tutorial-on-predictability/blob/main/EDIPI%20workshop%20qgs%20tutorial%20-%20Introduction.ipynb), qgs and the tutorial being installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use again the simple 2-layer channel QG atmosphere truncated at wavenumber 2 on a beta-plane with a simple orography (a montain and a valley), as in the Introduction notebook. But now, we are going to ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to load the model, and integrate it to find an initial condition on the attractor, as in the Introduction notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load some modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the model's modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qgs.params.params import QgParams\n",
    "from qgs.integrators.integrator import RungeKuttaIntegrator, RungeKuttaTglsIntegrator\n",
    "from qgs.functions.tendencies import create_tendencies\n",
    "from qgs.plotting.util import std_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qgs.diagnostics.streamfunctions import MiddleAtmosphericStreamfunctionDiagnostic\n",
    "from qgs.diagnostics.variables import VariablesDiagnostic\n",
    "from qgs.diagnostics.multi import MultiDiagnostic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define some general parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time increment parameter\n",
    "dt = 0.1\n",
    "# Saving the model state every 5 steps\n",
    "write_steps = 5\n",
    "# transient time\n",
    "transient_time = 10000.\n",
    "# integration time\n",
    "integration_time = 10000.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the model parameters object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = QgParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up some parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we define the latitude to be 50 degrees and a predefined amplitude of the meridional temperature gradient\n",
    "model_parameters.set_params({'phi0_npi': np.deg2rad(50.)/np.pi, 'hd':0.045})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and indicate that we want an atmospheric channel for the atmosphere, with Fourier modes up to wavenumber 2 in each spatial direction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters.set_atmospheric_channel_fourier_modes(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also set some topography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters.ground_params.set_orography(0.2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and indicate the amplitude of the meridional temperature gradient which forces the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters.atemperature_params.set_thetas(0.1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we are done configuring the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create the tendencies $\\boldsymbol{f}$ that will allow us to integrate the model equations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "f, Df = create_tendencies(model_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now integrate our model with the qgs built-in integrator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrator = RungeKuttaIntegrator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tell this integrator to use our defined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrator.set_func(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start from a small random initial condition and integrate over a transient time to obtain an initial condition on the attractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ic = np.random.rand(model_parameters.ndim)*0.1\n",
    "\n",
    "integrator.integrate(0., transient_time, dt, ic=ic, write_steps=0)  # write_steps=0 will only give us the last step\n",
    "time, ic = integrator.get_trajectories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then we can integrate the model starting from this initial condition in order to obtain a trajectory on the attractor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "integrator.integrate(0., 1000., dt, ic=ic, write_steps=write_steps)\n",
    "time, trajectory = integrator.get_trajectories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the output. First let's print the shape of trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trajectory.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dimension contains the different variables (20). The second dimension is time, and it contains the values of the variables along the integration, including the initial condition. Its length is therefore (integration_time/dt)/write_steps+1. In order to plot the time series of one variable, say for index 1, we have then to plot trajectory[1,:].\n",
    "\n",
    "What about time? The array time is in adimensional units. In order to plot a time series agains time expressed in dimensional units we have to multiply the time array by model_parameters.dimensional_time. We can then plot our time series against time expressed in days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(time*model_parameters.dimensional_time,trajectory[0,:],'b')\n",
    "plt.xlabel('time [days]')\n",
    "plt.ylabel('var1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed to analyse the predictability properties of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some theory before the exercises:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before working on the Lyapunov spectrum in the next parts of this tutorial, let's have a look at the aucorrelation function of our variable. The autocorrelation function is a useful statistical quantity in time series analysis that determines the properties of memory loss of a variable. \n",
    "\n",
    "The autocorrelation function of a stationary time series $x(t)$ with variance $\\sigma^2$ and mean $\\mu$=0 is\n",
    "\n",
    "$$ R(t) = \\frac{\\mathbb{E}\\left[x(s+t)x(s)\\right]}{\\sigma^2}$$\n",
    "\n",
    "where $s$ is an arbitrary time instant. Alternatively the autocorrelation function can be computed as a time integral\n",
    "\n",
    "$$ R(t)= \\lim_{T\\rightarrow +\\infty} \\,\\frac{1}{\\sigma^2} \\,\\int_0^T x(s+t)x(s)ds $$\n",
    "\n",
    "exploiting the equivalence of time and ensemble averages for a stationary process.\n",
    "\n",
    "The autocorrelation function determines the properties of memory loss of a process. Often one looks for an approximate behaviour \n",
    "\n",
    "$$ R(t) \\approx e^{-t/\\tau_0} $$\n",
    "\n",
    "at least for the first part of the function, in order to sinlgle out a characteritic time scale. An important quantity that charactherizes the memory properties of the process is the integral autocorrelation time $\\tau_c$\n",
    "\n",
    "$$ \\tau_c=\\lim_{T\\rightarrow +\\infty}\\int_0^T R(t)dt $$\n",
    "\n",
    "For a process with a perfectly exponential autocorrelation function the integral autocorrelation time coincides with the e-folding time scale. For a process with a more complicated autocorrelation function, it takes into account the contribution of possibly different decay rates in the tail. For some processes $\\tau_c$ may even be infinite (in the sense that the limit in the definition does not converge). In this case we say that the process has long term memory (in climate long term memory has been found for example in data related to rivers discharge). The first e-folding time scale and the integral autocorrelation time in general give a first idea in terms of orders of magnitude of the characteristic time scales of predictability of the dynamics. \n",
    "\n",
    "In order to compute the autocorrelation function we can use the correlate function of [Numpy](https://numpy.org/). [`numpy.correlate`](https://numpy.org/doc/stable/reference/generated/numpy.correlate.html) computes the cross correlation of two vectors. Using it to compute the correlation of a time series with itself and dividing by the variance of the time series we have a simple estimate of the autocorrelation function.\n",
    "\n",
    "Note: because of the way the [`numpy.correlate`](https://numpy.org/doc/stable/reference/generated/numpy.correlate.html) function works, we have to divide its output by the length of the original vector, and take the second half of the output (that will be twice the length of the original input vector).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a long trajectory of the system to estimate the autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the autocorrelation of a given variable of the model (for example the first one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot it as a function of the time and then integrate it to get the integral autocorrelation time $\\tau_c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can repeat this experiment with other variables. After that, you can also repeat this experiment but with different model parameters providing you a more chaotic atmosphere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The End."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
